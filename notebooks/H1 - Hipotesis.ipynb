{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipotesis No 1 a desarrollar en el ejercicio por Alvin Luperon\n",
    "#Para los estudiantes inscritos en el curso virtual AAA, se busca determinar si con el historial de combinación de compromiso conductual (clics totales, días activos, promedio de clics por día, score_avg, entre otras)\n",
    "# y características demográficas (puntuación promedio, créditos, género, región, nivel educativo, nivel socioeconómico y grupo de edad) de los años académicos 2013J y 2014J del dataset de OULAD\n",
    "# puede ser utilizada para:\n",
    "# Primero: Predecir por estudiante el estado de aprobado/reprobado en el año académico 2025J con un modelo de Regresión Logística.\n",
    "# Segundo: Estimar su puntuación final del curso en el año académico 2025J con un modelo de Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e603b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, auc, precision_recall_curve,\n",
    "    classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de los dataset, limpieza de dataset, manejo valores null o missing, uniones, manejo de variables categóricas y codificación ordinal\n",
    "\n",
    "# Rutas base de carpetas\n",
    "ruta = \"./oulad\"\n",
    "rutaEdaImg = \"./edaimg\"\n",
    "rutaDataPred = \"./datatopredict\"\n",
    "rutaOrdMapping = \"./ordmapping\"\n",
    "rutaResult_Pred = \"./result_pred\"\n",
    "rutaMetrics_models = \"./metrics_models\"\n",
    "\n",
    "# === 1. Cargar datos ===\n",
    "student_info = pd.read_csv(os.path.join(ruta, \"studentInfo.csv\"))\n",
    "student_registration = pd.read_csv(os.path.join(ruta, \"studentRegistration.csv\"))\n",
    "student_assessments = pd.read_csv(os.path.join(ruta, \"studentAssessment.csv\"))\n",
    "student_vle = pd.read_csv(os.path.join(ruta, \"studentVle.csv\"))\n",
    "\n",
    "print(\"✅ Datos cargados correctamente.\")\n",
    "\n",
    "# === 2. Filtrar por módulo \"AAA\" ===\n",
    "student_info = student_info[student_info[\"code_module\"] == \"AAA\"]\n",
    "student_vle = student_vle[student_vle[\"code_module\"] == \"AAA\"]\n",
    "student_ids = student_info[\"id_student\"]\n",
    "student_assessments = student_assessments[student_assessments[\"id_student\"].isin(student_ids)]\n",
    "student_registration = student_registration[student_registration[\"id_student\"].isin(student_ids)]\n",
    "\n",
    "print(\"✅ Datos filtrados por módulo 'AAA'.\")\n",
    "\n",
    "# === 3. Métricas de interacción con la plataforma ===\n",
    "# Convertir la columna 'date' a numérica, forzando errores a NaN\n",
    "student_vle[\"date\"] = pd.to_numeric(student_vle[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Calcular el total de clics por estudiante\n",
    "clicks = student_vle.groupby(\"id_student\")[\"sum_click\"].sum().reset_index(name=\"total_clicks\")\n",
    "\n",
    "# Calcular el número de días activos por estudiante\n",
    "active_days = student_vle.groupby(\"id_student\")[\"date\"].nunique().reset_index(name=\"active_days\")\n",
    "\n",
    "# Unir los totales de clics y días activos\n",
    "clicks_summary = pd.merge(clicks, active_days, on=\"id_student\", how=\"left\")\n",
    "\n",
    "# Calcular el promedio de clics por día activo, manejando divisiones por cero\n",
    "clicks_summary[\"avg_clicks_per_day\"] = clicks_summary[\"total_clicks\"] / clicks_summary[\"active_days\"].replace(0, pd.NA)\n",
    "\n",
    "print(\"✅ Métricas de interacción con la plataforma calculadas.\")\n",
    "\n",
    "# === 4. Métricas académicas ===\n",
    "# Convertir la columna 'score' a numérica, forzando errores a NaN\n",
    "student_assessments[\"score\"] = pd.to_numeric(student_assessments[\"score\"], errors=\"coerce\")\n",
    "\n",
    "# Calcular el promedio de score por estudiante\n",
    "avg_score = student_assessments.groupby(\"id_student\")[\"score\"].mean().reset_index(name=\"avg_score\")\n",
    "\n",
    "# Calcular el promedio y total de créditos estudiados por estudiante\n",
    "credits_summary = student_info.groupby(\"id_student\")[\"studied_credits\"].agg(\n",
    "    avg_credits=\"mean\", total_credits=\"sum\"\n",
    ").reset_index()\n",
    "\n",
    "print(\"✅ Métricas académicas calculadas.\")\n",
    "\n",
    "# === 5. Unir métricas ===\n",
    "summary = clicks_summary.merge(avg_score, on=\"id_student\", how=\"left\")\n",
    "summary = summary.merge(credits_summary, on=\"id_student\", how=\"left\")\n",
    "\n",
    "# Ajustar el promedio de créditos (dividir por 12, asumiendo 12 créditos por año estándar)\n",
    "summary[\"avg_credits\"] = summary[\"avg_credits\"] / 12\n",
    "\n",
    "print(\"✅ Métricas unidas y promedios ajustados.\")\n",
    "\n",
    "# === 6. Agregar variables categóricas ===\n",
    "categorical_cols = [\"gender\", \"region\", \"highest_education\", \"imd_band\", \"age_band\", \"final_result\", \"code_module\",\n",
    "                    \"code_presentation\"]\n",
    "student_categoricals = student_info[[\"id_student\"] + categorical_cols].drop_duplicates()\n",
    "summary = summary.merge(student_categoricals, on=\"id_student\", how=\"left\")\n",
    "\n",
    "print(\"✅ Variables categóricas agregadas.\")\n",
    "\n",
    "# === 7. Codificación ordinal y guardado de mappings en un solo archivo ===\n",
    "\n",
    "# Definir los mappings para cada variable categórica\n",
    "gender_mapping = {\"M\": 0, \"F\": 1}\n",
    "region_mapping = {v: i for i, v in enumerate(sorted(summary[\"region\"].dropna().unique()))}\n",
    "highest_education_mapping = {v: i for i, v in enumerate(sorted(summary[\"highest_education\"].dropna().unique()))}\n",
    "imd_band_mapping = {v: i for i, v in enumerate(sorted(summary[\"imd_band\"].dropna().unique()))}\n",
    "age_band_mapping = {v: i for i, v in enumerate(sorted(summary[\"age_band\"].dropna().unique()))}\n",
    "\n",
    "# Aplicar la codificación ordinal al DataFrame principal\n",
    "summary[\"gender_ordinal\"] = summary[\"gender\"].map(gender_mapping)\n",
    "summary[\"region_ordinal\"] = summary[\"region\"].map(region_mapping)\n",
    "summary[\"highest_education_ordinal\"] = summary[\"highest_education\"].map(highest_education_mapping)\n",
    "summary[\"imd_band_ordinal\"] = summary[\"imd_band\"].map(imd_band_mapping)\n",
    "summary[\"age_band_ordinal\"] = summary[\"age_band\"].map(age_band_mapping)\n",
    "\n",
    "# Crear una lista para almacenar DataFrames de cada mapeo\n",
    "all_mappings_dfs = []\n",
    "\n",
    "# Añadir cada mapeo a la lista con nombres de columna apropiados\n",
    "# Género\n",
    "df_gender_map = pd.DataFrame(gender_mapping.items(), columns=['valor_original', 'valor_ordinal'])\n",
    "df_gender_map['variable_categorica'] = 'gender'\n",
    "all_mappings_dfs.append(df_gender_map)\n",
    "\n",
    "# Región\n",
    "df_region_map = pd.DataFrame(region_mapping.items(), columns=['valor_original', 'valor_ordinal'])\n",
    "df_region_map['variable_categorica'] = 'region'\n",
    "all_mappings_dfs.append(df_region_map)\n",
    "\n",
    "# Nivel educativo más alto\n",
    "df_edu_map = pd.DataFrame(highest_education_mapping.items(), columns=['valor_original', 'valor_ordinal'])\n",
    "df_edu_map['variable_categorica'] = 'highest_education'\n",
    "all_mappings_dfs.append(df_edu_map)\n",
    "\n",
    "# Banda IMD\n",
    "df_imd_map = pd.DataFrame(imd_band_mapping.items(), columns=['valor_original', 'valor_ordinal'])\n",
    "df_imd_map['variable_categorica'] = 'imd_band'\n",
    "all_mappings_dfs.append(df_imd_map)\n",
    "\n",
    "# Banda de edad\n",
    "df_age_map = pd.DataFrame(age_band_mapping.items(), columns=['valor_original', 'valor_ordinal'])\n",
    "df_age_map['variable_categorica'] = 'age_band'\n",
    "all_mappings_dfs.append(df_age_map)\n",
    "\n",
    "# Concatenar todos los DataFrames de mapeo en un solo DataFrame\n",
    "all_ordinal_mappings_df = pd.concat(all_mappings_dfs, ignore_index=True)\n",
    "\n",
    "# Reordenar las columnas para que 'variable_categorica' sea la primera\n",
    "all_ordinal_mappings_df = all_ordinal_mappings_df[['variable_categorica', 'valor_original', 'valor_ordinal']]\n",
    "\n",
    "# Guardar el DataFrame combinado en un único archivo CSV\n",
    "all_ordinal_mappings_df.to_csv(os.path.join(rutaOrdMapping, 'all_ordinal_mappings.csv'), index=False)\n",
    "\n",
    "print(\"✅ Todos los mappings de codificación ordinal guardados en 'all_ordinal_mappings.csv'.\")\n",
    "\n",
    "# === 8. Variable binaria de aprobación ===\n",
    "summary[\"passed\"] = summary[\"final_result\"].apply(lambda x: 1 if x in [\"Pass\", \"Distinction\"] else 0)\n",
    "\n",
    "print(\"✅ Variable binaria de aprobación 'passed' creada.\")\n",
    "\n",
    "# === 9. Limpieza y orden de columnas ===\n",
    "# Eliminar las columnas categóricas originales, ya que ahora tenemos sus versiones ordinales\n",
    "summary = summary.drop(columns=[\"gender\", \"region\", \"highest_education\", \"imd_band\", \"age_band\", \"final_result\"],\n",
    "                       errors=\"ignore\")\n",
    "\n",
    "# Reordenar las columnas para mayor claridad\n",
    "cols = list(summary.columns)\n",
    "if all(col in cols for col in [\"id_student\", \"code_module\", \"code_presentation\"]):\n",
    "    cols.remove(\"code_module\")\n",
    "    cols.remove(\"code_presentation\")\n",
    "    id_index = cols.index(\"id_student\") + 1\n",
    "    cols = cols[:id_index] + [\"code_module\", \"code_presentation\"] + cols[id_index:]\n",
    "    summary = summary[cols]\n",
    "\n",
    "print(\"✅ Columnas limpiadas y reordenadas.\")\n",
    "\n",
    "# === 0. Eliminar filas con valores faltantes ===\n",
    "summary.dropna(subset=[\n",
    "    \"total_clicks\", \"active_days\", \"avg_clicks_per_day\", \"avg_score\",\n",
    "    \"gender_ordinal\", \"region_ordinal\", \"highest_education_ordinal\",\n",
    "    \"imd_band_ordinal\", \"age_band_ordinal\", \"passed\", \"avg_credits\", \"total_credits\",\n",
    "])\n",
    "\n",
    "# === 10. Guardar resultados ===\n",
    "\n",
    "summary.to_csv(os.path.join(ruta, \"H1 - oulad_click_summary_AAA_course.csv\"), index=False)\n",
    "print(\"✅ Archivo final guardado como 'oulad_click_summary_AAA_course.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4dd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar los dataset a utilizar y hacer analisis descriptivos de los mismos\n",
    "\n",
    "#  Cargar los datos de entrenamiento\n",
    "df_train = summary\n",
    "# Cargar el dataset de predicción\n",
    "df_predict = pd.read_csv(os.path.join(rutaDataPred, \"datasetapredecir.csv\"))\n",
    "\n",
    "# Mostrar información general de los DataFrames de entrenamiento \n",
    "df_train.info()\n",
    "df_train.describe().to_csv(os.path.join(ruta, \"H1 - resumen_estadistico_oulad_click_summary_AAA_course.csv\"))\n",
    "\n",
    "# Mostrar información general de los DataFrames de predicción \n",
    "df_predict.info()\n",
    "df_predict.describe().to_csv(os.path.join(rutaDataPred, \"H1 - resumen_estadistico_datasetapredecir.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df_train  # Reemplaza con el nombre real de tu archivo\n",
    "mappings_df = all_ordinal_mappings_df\n",
    "\n",
    "# Crear diccionario de mapeos\n",
    "mapping_dict = {}\n",
    "for var in mappings_df['variable_categorica'].unique():\n",
    "    sub_df = mappings_df[mappings_df['variable_categorica'] == var]\n",
    "    mapping_dict[var] = dict(zip(sub_df['valor_ordinal'], sub_df['valor_original']))\n",
    "\n",
    "# Variables categóricas y numéricas\n",
    "categorical_vars = [\n",
    "    'gender_ordinal', 'region_ordinal',\n",
    "    'highest_education_ordinal', 'imd_band_ordinal', 'age_band_ordinal', 'passed'\n",
    "]\n",
    "numeric_vars = [\n",
    "    'avg_score', 'total_clicks', 'active_days', 'avg_clicks_per_day', 'total_credits', 'avg_credits'\n",
    "]\n",
    "\n",
    "# Inicializar listas para almacenar resultados\n",
    "anova_data = []\n",
    "ttest_data = []\n",
    "\n",
    "# Pruebas estadísticas\n",
    "for cat_var in categorical_vars:\n",
    "    if cat_var not in df_train.columns:\n",
    "        continue\n",
    "    for num_var in numeric_vars:\n",
    "        if num_var not in df_train.columns:\n",
    "            continue\n",
    "        groups = [group[num_var].dropna() for name, group in df_train.groupby(cat_var)]\n",
    "        if len(groups) > 1:\n",
    "            f_stat, p_val = stats.f_oneway(*groups)\n",
    "            anova_data.append({\n",
    "                'Variable': num_var,\n",
    "                'Agrupado_por': cat_var,\n",
    "                'F-statistic': f_stat,\n",
    "                'p-value': p_val\n",
    "            })\n",
    "        if df_train[cat_var].nunique() == 2:\n",
    "            unique_vals = df_train[cat_var].dropna().unique()\n",
    "            group1 = df_train[df_train[cat_var] == unique_vals[0]][num_var].dropna()\n",
    "            group2 = df_train[df_train[cat_var] == unique_vals[1]][num_var].dropna()\n",
    "            if len(group1) > 1 and len(group2) > 1:\n",
    "                t_stat, p_val = stats.ttest_ind(group1, group2)\n",
    "                ttest_data.append({\n",
    "                    'Variable': num_var,\n",
    "                    'Agrupado_por': cat_var,\n",
    "                    'T-statistic': t_stat,\n",
    "                    'p-value': p_val\n",
    "                })\n",
    "\n",
    "# Convertir resultados en DataFrames\n",
    "anova_df = pd.DataFrame(anova_data)\n",
    "ttest_df = pd.DataFrame(ttest_data)\n",
    "\n",
    "# Convertir los resultados a formato horizontal (pivotar por agrupación)\n",
    "anova_horizontal = anova_df.pivot(index='Variable', columns='Agrupado_por', values='p-value')\n",
    "ttest_horizontal = ttest_df.pivot(index='Variable', columns='Agrupado_por', values='p-value')\n",
    "\n",
    "# Formatear los valores p con 6 decimales sin notación científica\n",
    "anova_horizontal = anova_horizontal.map(lambda x: f\"{x:.6f}\")\n",
    "ttest_horizontal = ttest_horizontal.map(lambda x: f\"{x:.6f}\")\n",
    "\n",
    "# Restablecer el índice para que 'Variable' sea una columna\n",
    "anova_horizontal.reset_index(inplace=True)\n",
    "ttest_horizontal.reset_index(inplace=True)\n",
    "\n",
    "# Guardar resultados si se desea\n",
    "anova_horizontal.to_csv(os.path.join(rutaResult_Pred, \"H1 - TestDataSet_resultados_anova.csv\"), index=False)\n",
    "ttest_horizontal.to_csv(os.path.join(rutaResult_Pred, \"H1 - TestDataSet_resultados_ttest.csv\"), index=False)\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print(\"Resultados ANOVA:\")\n",
    "display(anova_horizontal)\n",
    "\n",
    "print(\"\\nResultados T-test:\")\n",
    "display(ttest_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras y variable objetivo\n",
    "features = [\n",
    "    'total_clicks', 'active_days', 'avg_clicks_per_day',\n",
    "    'avg_credits', 'total_credits',\n",
    "    'gender_ordinal', 'region_ordinal',\n",
    "    'highest_education_ordinal', 'imd_band_ordinal', 'age_band_ordinal'\n",
    "]\n",
    "X = df_train[features]\n",
    "y = df_train['passed']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 4. Validación básica ===\n",
    "print(\"✅ Variables predictoras:\", list(X.columns))\n",
    "print(\"Distribución de la variable objetivo:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipotesis 1 - parte 1: Predecir su estado de aprobado/reprobado en el año académico 2025J con un modelo de Regresión Logística.\n",
    "\n",
    "#Modelo de regresión logística\n",
    "\n",
    "# Entrenar modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=3000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Entrenar modelo\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calcular métricas de evaluación\n",
    "mse = mean_squared_error(y_test, y_proba)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_proba)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# crear un DataFrame para las métricas\n",
    "metrics = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"MSE\", \"RMSE\", \"R² Score\"],\n",
    "    \"Value\": [accuracy, precision, recall, f1, mse, rmse, r2]\n",
    "}\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "# Guardar las métricas en un archivo CSV\n",
    "df_metrics.to_csv(os.path.join(rutaMetrics_models, \"H1 - logistic_regression_metrics.csv\"), index=False)\n",
    "\n",
    "# imprimir las métricas\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Aplicar el modelo para predecir\n",
    "X_pred = df_predict[features]\n",
    "df_predict['predicted_passed'] = model.predict(X_pred)\n",
    "\n",
    "# Guardar resultados\n",
    "df_predict.to_csv(os.path.join(rutaResult_Pred, \"H1 - Regresión Logística pred_estudiantes pass or not.csv\"),\n",
    "                  index=False)\n",
    "print(\"\\nH1 - Regresión Logística pred_estudiantes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficas de metricas del modelo\n",
    "#estilo de gráficos\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"husl\")\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Crear figura con 3 gráficos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Matriz de confusión\n",
    "disp_cm = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp_cm.plot(ax=axes[0], cmap=\"cividis\", colorbar=False)\n",
    "axes[0].set_title(\"Matriz de Confusión\")\n",
    "\n",
    "# Curva ROC\n",
    "axes[1].plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[1].set_title(\"Curva ROC\")\n",
    "axes[1].set_xlabel(\"False Positive Rate\")\n",
    "axes[1].set_ylabel(\"True Positive Rate\")\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "# Curva Precisión-Recall\n",
    "axes[2].plot(recall, precision)\n",
    "axes[2].set_title(\"Curva Precisión-Recall\")\n",
    "axes[2].set_xlabel(\"Recall\")\n",
    "axes[2].set_ylabel(\"Precision\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1 - Regresión Logística - Métricas del Modelo.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffac352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis exploratorio EDA por variables ordinales\n",
    "\n",
    "# Cargar los datos de predicción y los mappings\n",
    "df = df_predict\n",
    "mappings = all_ordinal_mappings_df\n",
    "\n",
    "# Variables ordinales\n",
    "ordinal_columns = [\n",
    "    'gender_ordinal', 'region_ordinal',\n",
    "    'highest_education_ordinal', 'imd_band_ordinal', 'age_band_ordinal'\n",
    "]\n",
    "\n",
    "# Crear diccionarios de mapeo\n",
    "mapping_dicts = {}\n",
    "for col in ordinal_columns:\n",
    "    var_name = col.replace('_ordinal', '')\n",
    "    mapping = mappings[mappings['variable_categorica'] == var_name][['valor_ordinal', 'valor_original']]\n",
    "    mapping_dicts[col] = dict(zip(mapping['valor_ordinal'], mapping['valor_original']))\n",
    "\n",
    "# Reemplazar valores ordinales por etiquetas\n",
    "for col in ordinal_columns:\n",
    "    df[col] = df[col].map(mapping_dicts[col])\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Gráfico 1: Boxplot con colores verde (aprobado) y rojo (no aprobado)\n",
    "palette_box = {0: \"red\", 1: \"green\"}\n",
    "sns.boxplot(x='age_band_ordinal', y='total_clicks', hue='predicted_passed', data=df, ax=axes[0], palette=palette_box)\n",
    "axes[0].set_title('Total Clicks por Edad y Predicción')\n",
    "axes[0].set_xlabel('Grupo de Edad')\n",
    "axes[0].set_ylabel('Total Clicks')\n",
    "\n",
    "# Corregir leyenda manualmente\n",
    "handles, _ = axes[0].get_legend_handles_labels()\n",
    "axes[0].legend(handles=handles, labels=['No Aprobó', 'Sí Aprobó'], title='¿Aprobó?')\n",
    "\n",
    "# Gráfico 2: Barras horizontales apiladas por nivel educativo\n",
    "edu_counts = df.groupby(['highest_education_ordinal', 'predicted_passed']).size().unstack(fill_value=0)\n",
    "edu_props = edu_counts.div(edu_counts.sum(axis=1), axis=0)\n",
    "edu_props = edu_props.loc[edu_props.sum(axis=1).sort_values().index]\n",
    "\n",
    "axes[1].barh(edu_props.index, edu_props[0], color='red', label='No Aprobó')\n",
    "axes[1].barh(edu_props.index, edu_props[1], left=edu_props[0], color='green', label='Sí Aprobó')\n",
    "\n",
    "for i, (rej, apr) in enumerate(zip(edu_props[0], edu_props[1])):\n",
    "    axes[1].text(rej / 2, i, f'{rej:.0%}', va='center', ha='center', color='white', fontsize=9)\n",
    "    axes[1].text(rej + apr / 2, i, f'{apr:.0%}', va='center', ha='center', color='white', fontsize=9)\n",
    "\n",
    "axes[1].set_title('Proporción de Aprobados por Nivel Educativo')\n",
    "axes[1].set_xlabel('Proporción')\n",
    "axes[1].set_ylabel('Nivel Educativo')\n",
    "axes[1].legend(title='Predicción')\n",
    "\n",
    "# Gráfico 3: Proporción de aprobados por región y género\n",
    "region_gender = df.groupby(['region_ordinal', 'gender_ordinal'])['predicted_passed'].mean().reset_index()\n",
    "region_gender_pivot = region_gender.pivot(index='region_ordinal', columns='gender_ordinal', values='predicted_passed')\n",
    "region_gender_pivot.plot(kind='bar', ax=axes[2], color=['#1f77b4', '#ff7f0e'])\n",
    "\n",
    "axes[2].set_title('Proporción de Aprobados por Región y Género')\n",
    "axes[2].set_xlabel('Región')\n",
    "axes[2].set_ylabel('Proporción de Aprobados')\n",
    "axes[2].legend(title='Género', labels=['M', 'F'], loc='lower right')\n",
    "axes[2].set_xticklabels(region_gender_pivot.index, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1 - EDA - Variables Ordinales.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis y clustering de los datos de estudiantes\n",
    "\n",
    "# Cargar los datos\n",
    "df = df_predict\n",
    "\n",
    "# Variables numéricas para análisis y clustering\n",
    "numeric_cols = ['total_clicks', 'active_days', 'avg_clicks_per_day',\n",
    "                'total_credits', 'avg_credits', 'predicted_passed']\n",
    "features = ['total_clicks', 'active_days', 'avg_clicks_per_day',\n",
    "            'total_credits', 'avg_credits']\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[numeric_cols])\n",
    "X_scaled_features = scaler.fit_transform(df[features])\n",
    "\n",
    "# PCA para reducción de dimensionalidad\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "pca_3d = PCA(n_components=3)\n",
    "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled_features)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# Calcular resumen por cluster\n",
    "cluster_summary = df.groupby('cluster').agg({\n",
    "    'total_clicks': 'mean',\n",
    "    'active_days': 'mean',\n",
    "    'avg_clicks_per_day': 'mean',\n",
    "    'total_credits': 'mean',\n",
    "    'avg_credits': 'mean',\n",
    "    'predicted_passed': lambda x: round(x.mean() * 100, 2)\n",
    "}).rename(columns={'predicted_passed': 'approval_rate (%)'})\n",
    "\n",
    "cluster_summary = cluster_summary.round(2)\n",
    "\n",
    "# Mostrar el resumen\n",
    "print(\"Resumen de Perfiles de Clusters:\")\n",
    "display(cluster_summary)\n",
    "\n",
    "# Guardar el resumen de clusters en un archivo CSV\n",
    "cluster_summary.to_csv(os.path.join(rutaResult_Pred, \"H1 - Clustering resumen perfiles clusters.csv\"), index=True)\n",
    "\n",
    "# Preparar figura\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Gráfico 1: Matriz de correlación\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "corr = df[numeric_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax1)\n",
    "ax1.set_title(\"Matriz de Correlación\")\n",
    "\n",
    "# Gráfico 2: Clustering con PCA 2D\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "scatter = ax2.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=clusters, cmap='Set1', alpha=0.7)\n",
    "ax2.set_title(\"Clustering de Estudiantes (PCA 2D)\")\n",
    "ax2.set_xlabel(\"PCA 1\")\n",
    "ax2.set_ylabel(\"PCA 2\")\n",
    "\n",
    "# Gráfico 3: Dispersión 3D con PCA\n",
    "ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "scatter3d = ax3.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],\n",
    "                        c=clusters, cmap='Set1', alpha=0.7)\n",
    "ax3.set_title(\"Dispersión 3D por Cluster (PCA)\")\n",
    "ax3.set_xlabel(\"PCA 1\")\n",
    "ax3.set_ylabel(\"PCA 2\")\n",
    "ax3.set_zlabel(\"PCA 3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1 - Clustering y Análisis de Estudiantes.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipotesis 1 - parte 2: Estimar su puntuación final del curso en el año académico 2025J con un modelo de Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c65358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "historical_df = summary\n",
    "future_df = pd.read_csv(os.path.join(rutaDataPred, \"datasetapredecir.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc563238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características y variable objetivo\n",
    "features = [\n",
    "    'total_clicks', 'active_days', 'avg_clicks_per_day', 'avg_credits', 'total_credits',\n",
    "    'gender_ordinal', 'region_ordinal', 'highest_education_ordinal',\n",
    "    'imd_band_ordinal', 'age_band_ordinal'\n",
    "]\n",
    "target = 'avg_score'\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "historical_df = historical_df.dropna(subset=features + [target])\n",
    "\n",
    "# Eliminar outliers usando el método IQR\n",
    "Q1 = historical_df[target].quantile(0.25)\n",
    "Q3 = historical_df[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "filtered_df = historical_df[(historical_df[target] >= lower_bound) & (historical_df[target] <= upper_bound)]\n",
    "\n",
    "# Separar variables y etiquetas\n",
    "X = filtered_df[features]\n",
    "y = filtered_df[target]\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo RandomForest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación del modelo\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== Métricas del Modelo RandomForest (sin outliers) ===\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"MSE:  {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²:   {r2:.2f}\")\n",
    "\n",
    "# Clasificación binaria basada en score >= 70\n",
    "y_test_class = y_test.apply(lambda x: 1 if x >= 70 else 0)\n",
    "y_pred_class = pd.Series(y_pred).apply(lambda x: 1 if x >= 70 else 0)\n",
    "\n",
    "# Métricas de clasificación\n",
    "acc = accuracy_score(y_test_class, y_pred_class)\n",
    "prec = precision_score(y_test_class, y_pred_class)\n",
    "rec = recall_score(y_test_class, y_pred_class)\n",
    "f1 = f1_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"\\n=== Métricas de Clasificación Derivadas del Score ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# crear un DataFrame para las métricas\n",
    "metrics = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"MAE\", \"MSE\", \"RMSE\", \"R² Score\"],\n",
    "    \"Value\": [acc, prec, rec, f1, mae, mse, rmse, r2]\n",
    "}\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "# Guardar las métricas en un archivo CSV\n",
    "df_metrics.to_csv(os.path.join(rutaMetrics_models, \"H1.2- random_forest_regressor_metrics.csv\"), index=False)\n",
    "\n",
    "# Aplicar modelo al dataset de 2025J\n",
    "X_future = future_df[features]\n",
    "future_df['predicted_score'] = rf_model.predict(X_future)\n",
    "\n",
    "\n",
    "# Clasificación detallada\n",
    "def clasificar(score):\n",
    "    if score <= 60:\n",
    "        return 'No Aprobado'\n",
    "    elif 60 < score <= 70:\n",
    "        return 'En Recuperación'\n",
    "    elif 70 < score <= 90:\n",
    "        return 'Aprobado'\n",
    "    else:\n",
    "        return 'Honorífico'\n",
    "\n",
    "\n",
    "future_df['clasificacion'] = future_df['predicted_score'].apply(clasificar)\n",
    "\n",
    "# Exportar dataset enriquecido\n",
    "future_df.to_csv(os.path.join(rutaResult_Pred, \"H1.2 - Random Forest pred_estudiantes score.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gráficos de métricas del modelo Random Forest\n",
    "\n",
    "#estilo de gráficos\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"husl\")\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "\n",
    "# Importancia de variables\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Crear visualizaciones\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Matriz de confusión\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusión')\n",
    "axes[0].set_xlabel('Predicción')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Importancia de variables\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, ax=axes[1], palette='viridis')\n",
    "axes[1].set_title('Importancia de Variables')\n",
    "\n",
    "# Score real vs predicho\n",
    "axes[2].scatter(y_test, y_pred, alpha=0.6)\n",
    "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[2].set_xlabel('Score Real')\n",
    "axes[2].set_ylabel('Score Predicho')\n",
    "axes[2].set_title('Score Real vs. Score Predicho')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1.2 - Random Forest - Métricas del Modelo.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estilo de gráficos\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"husl\")\n",
    "\n",
    "# Análisis de errores del modelo Random Forest\n",
    "errors = y_test - y_pred\n",
    "abs_errors = np.abs(errors)\n",
    "\n",
    "# Crear visualizaciones\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Error absoluto por score real\n",
    "axes[0].scatter(y_test, abs_errors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel(\"Score Real\")\n",
    "axes[0].set_ylabel(\"Error Absoluto\")\n",
    "axes[0].set_title(\"Error Absoluto vs. Score Real\")\n",
    "\n",
    "# 2. Histograma de errores\n",
    "sns.histplot(errors, bins=20, kde=True, ax=axes[1], color='orange')\n",
    "axes[1].set_title(\"Distribución de Errores (Score Real - Predicho)\")\n",
    "axes[1].set_xlabel(\"Error\")\n",
    "\n",
    "# 3. Curva de residuos\n",
    "axes[2].scatter(y_pred, errors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "axes[2].axhline(0, color='red', linestyle='--')\n",
    "axes[2].set_xlabel(\"Score Predicho\")\n",
    "axes[2].set_ylabel(\"Residuo\")\n",
    "axes[2].set_title(\"Curva de Residuos\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1.2 - Random Forest - Análisis de Errores.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0991b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analisis exploratorio EDA por variables ordinales\n",
    "\n",
    "# Estilo visual\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Cargar los datos\n",
    "df = future_df\n",
    "mappings = all_ordinal_mappings_df\n",
    "\n",
    "# Crear diccionarios de mapeo\n",
    "region_map = mappings[mappings['variable_categorica'] == 'region'].set_index('valor_ordinal')[\n",
    "    'valor_original'].to_dict()\n",
    "gender_map = mappings[mappings['variable_categorica'] == 'gender'].set_index('valor_ordinal')[\n",
    "    'valor_original'].to_dict()\n",
    "education_map = mappings[mappings['variable_categorica'] == 'highest_education'].set_index('valor_ordinal')[\n",
    "    'valor_original'].to_dict()\n",
    "\n",
    "# Aplicar los mapeos\n",
    "df['region'] = df['region_ordinal'].map(region_map)\n",
    "df['gender'] = df['gender_ordinal'].map(gender_map)\n",
    "df['education'] = df['highest_education_ordinal'].map(education_map)\n",
    "\n",
    "# Crear los gráficos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Boxplot por región\n",
    "sns.boxplot(data=df, x='region', y='predicted_score', hue='region', palette='pastel', ax=axes[0], legend=False)\n",
    "axes[0].set_title('Distribución del Score por Región', fontsize=14)\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Violinplot por género\n",
    "sns.violinplot(data=df, x='gender', y='predicted_score', hue='gender', palette='Set3', ax=axes[1], legend=False)\n",
    "axes[1].set_title('Distribución del Score por Género', fontsize=14)\n",
    "\n",
    "# Barplot por nivel educativo\n",
    "mean_scores = df.groupby('education')['predicted_score'].mean().reset_index()\n",
    "sns.barplot(data=mean_scores, x='education', y='predicted_score', hue='education', palette='muted', ax=axes[2],\n",
    "            legend=False)\n",
    "axes[2].set_title('Promedio del Score por Nivel Educativo', fontsize=14)\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1.2 - EDA - Variables Ordinales.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis exploratorio EDA por clustering\n",
    "\n",
    "# Cargar los datos\n",
    "df = future_df\n",
    "\n",
    "# Definir combinaciones de variables para clustering\n",
    "features = [\n",
    "    (\"predicted_score\", \"avg_credits\"),\n",
    "    (\"predicted_score\", \"total_clicks\"),\n",
    "    (\"predicted_score\", \"avg_clicks_per_day\")\n",
    "]\n",
    "\n",
    "# Estilo visual\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"husl\", 3)\n",
    "\n",
    "# Crear figura\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Generar gráficos con mejoras visuales\n",
    "for i, (x_var, y_var) in enumerate(features):\n",
    "    data = df[[x_var, y_var]].copy()\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    # KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_scaled)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    centroids_original = scaler.inverse_transform(centroids)\n",
    "\n",
    "    cluster_col = f'cluster_{i + 1}'\n",
    "    df[cluster_col] = clusters\n",
    "\n",
    "    # Gráfico de dispersión\n",
    "    sns.scatterplot(\n",
    "        x=x_var,\n",
    "        y=y_var,\n",
    "        hue=cluster_col,\n",
    "        size='active_days',\n",
    "        sizes=(20, 200),\n",
    "        palette=palette,\n",
    "        data=df,\n",
    "        ax=axes[i],\n",
    "        edgecolor='black',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    # Centroides\n",
    "    axes[i].scatter(\n",
    "        centroids_original[:, 0],\n",
    "        centroids_original[:, 1],\n",
    "        s=250,\n",
    "        c='black',\n",
    "        marker='X',\n",
    "        label='Centroides'\n",
    "    )\n",
    "\n",
    "    # Anotaciones de centroides\n",
    "    for j, (cx, cy) in enumerate(centroids_original):\n",
    "        axes[i].annotate(f'C{j}', (cx, cy), textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=10,\n",
    "                         color='black')\n",
    "\n",
    "    axes[i].set_title(f'Clustering: {x_var} vs {y_var}', fontsize=14)\n",
    "    axes[i].legend(title='Cluster', loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(rutaEdaImg, \"H1.2 - Clustering y Analisis de Estudiantes por score.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Lista para almacenar descripciones de clusters\n",
    "cluster_descriptions = []\n",
    "\n",
    "# Aplicar clustering y generar descripciones\n",
    "for i, (x_var, y_var) in enumerate(features):\n",
    "    data = df[[x_var, y_var]].copy()\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    # KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_scaled)\n",
    "    cluster_col = f'cluster_{i + 1}'\n",
    "    df[cluster_col] = clusters\n",
    "\n",
    "    # Descripción estadística por cluster\n",
    "    desc = df.groupby(cluster_col)[[x_var, y_var]].agg(['mean', 'std', 'count']).reset_index()\n",
    "    desc.columns = ['cluster_id'] + [f\"{col[0]} ({col[1]})\" for col in desc.columns[1:]]\n",
    "    desc.insert(0, 'cluster_type', cluster_col)\n",
    "    cluster_descriptions.append(desc)\n",
    "\n",
    "# Combinar todas las descripciones en un solo DataFrame\n",
    "combined_description = pd.concat(cluster_descriptions, ignore_index=True)\n",
    "\n",
    "# Mostrar la tabla combinada\n",
    "display(combined_description)\n",
    "combined_description.to_csv(os.path.join(rutaResult_Pred, \"H1.2 - Clustering resumen perfiles clusters.csv\"),\n",
    "                            index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
